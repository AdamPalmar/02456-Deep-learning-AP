{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Exercise\n",
    "\n",
    "For this exercise we will be using the [OpenAI Gym](https://gym.openai.com/) provided by [OpenAI](https://openai.com/). To get to know Gym, you are encouraged to read this [blogpost](https://openai.com/blog/openai-gym-beta/) (~10 minutes) and refer to the [docs](https://gym.openai.com/docs) along the way.\n",
    "\n",
    "In this exercise we will train a neural network agent to navigate various environments from the OpenAI Gym.\n",
    "\n",
    "## 0. Prerequisites\n",
    "\n",
    "We assume you already have Theano and Lasagne installed -- otherwise go back to the first exercise for instructions. \n",
    "\n",
    "Below is a brief guide on how to install OpenAI Gym. For more details please refer to the [docs](https://gym.openai.com/docs).\n",
    "   \n",
    "```\n",
    "$ cd ~/path/to/dir/...\n",
    "$ git clone https://github.com/openai/gym\n",
    "$ cd gym\n",
    "$ pip install -e . # minimal install\n",
    "```\n",
    "\n",
    "Verify your installation is working by importing `gym` and check for errors:\n",
    "\n",
    "```\n",
    "$ python\n",
    ">>> import gym\n",
    "[no errors]\n",
    "```\n",
    "\n",
    "Now restart this notebook before moving on to the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting started\n",
    "\n",
    "Now that you have everythong installed, lets get started!\n",
    "\n",
    "The code below will import `gym` and initialize the [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) environment. The task of this environment is to move a cart in order to balance a pole attached on top, but for now we will just take random actions for 200 timesteps to see what happens. The environment is rendered in a separate window so you can observe the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-10-03 13:21:08,793] Making new env: CartPole-v0\n",
      "[2016-10-03 13:21:08,878] You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# init and run an example environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample())\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was all very nice, but taking random actions doesn't really solve the task. We have to do something smarter. In the next part we will train an agent to solve the task by reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Policy gradient agent\n",
    "\n",
    "In this part we will create an agent that can learn to solve tasks from OpenAI Gym by applying the policy gradient method.\n",
    "\n",
    "The agent is designed to work on environments with a discrete action space. Extending the code to also handle environments with countinous action space is left as an optional exercise.\n",
    "\n",
    "But first here is a short introduction to policy gradients.\n",
    "\n",
    "### Policy gradients\n",
    "\n",
    "We want to learn a policy neural network $p_\\theta(a_{t}|s_{t-1})$ with parameters $\\theta$ for action $a_t$ given the previous state $s_{t-1}$ only.\n",
    "When the action $a$ is discrete we can implement this by a softmax output taking $s$ as input. \n",
    "The (discounted) cumulative award for a sequence terminating after $T$ time-steps is\n",
    "\n",
    "$$\n",
    "R = \\sum_{t=1}^T \\gamma^{t-1} r_{t} \\ .\n",
    "$$\n",
    "\n",
    "The expectation of $R$ over a\n",
    "policy roll-out $p_\\theta({\\bf a}|{\\bf s})$ is \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[R|\\theta] = \\int R({\\bf a},{\\bf s}) p_\\theta({\\bf a},{\\bf s}) d{\\bf a} d{\\bf s}\\ ,\n",
    "$$\n",
    "\n",
    "where ${\\bf a} = a_1,\\ldots,a_T$, ${\\bf s}=s_0,\\ldots,s_T$ and\n",
    "\n",
    "$$\n",
    "p_\\theta({\\bf a},{\\bf s}) = p(s_0) \\prod_{t=1}^T \\left[ \n",
    "p(s_{t}|s_{t-1},a_t) p_\\theta(a_{t}|s_{t-1})\n",
    "\\right]\\ .\n",
    "$$\n",
    "\n",
    "In this formulation $s_t$ is a stochastic function of the previous action and state: $p(s_t|a_t,s_{t-1})$. We can draw from the joint distribution of actions and states through the environment but $p(s_t|a_t,s_{t-1})$ is unknown. \n",
    "\n",
    "A deterministic environment, think chess or go, is a special case of this set-up where the state is a deterministic function of the previous state and action: $s_t = f(a_t,s_{t-1})$. We can include the deterministic formulation in the general by using a Dirac $\\delta$-function: $p(s_t|a_t,s_{t-1})= \\delta(s_t - f(a_t,s_{t-1}))$. The integration over $s_1,\\ldots,s_T$ may be carried out explicitly:    \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[R|\\theta] = \\int R({\\bf a},s_0) p(s_0) \\prod_{t=1}^T  p_\\theta(a_{t}|s_{t-1})d{\\bf a} ds_0\\ ,\n",
    "$$\n",
    "\n",
    "where $s_{t-1}=f(a_{t-1},s_{t-2})$.\n",
    "\n",
    "We use gradient ascent to learn an approximation to a policy that maximizes the cumulative reward. \n",
    "So we need to compute the gradient:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\mathbb{E}[R|\\theta] = \\int R({\\bf a}, {\\bf s}) \\nabla_\\theta p_\\theta({\\bf a},{\\bf s}) \\, d{\\bf a}d{\\bf s} \\ .\n",
    "$$\n",
    "\n",
    "We can now use the identity\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta p_\\theta({\\bf a},{\\bf s}) = p_\\theta({\\bf a},{\\bf s}) \\nabla_\\theta \\log p_\\theta({\\bf a},{\\bf s})\n",
    "$$\n",
    "\n",
    "to express the gradient as an average over $p_\\theta({\\bf a},{\\bf s})$:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\mathbb{E}[R|\\theta] = \\int p_\\theta({\\bf a},{\\bf s}) ( R({\\bf a}, {\\bf s}) - b ) \\nabla_\\theta \\log p_\\theta({\\bf a},{\\bf s}) d{\\bf a}d{\\bf s}\\ .\n",
    "$$\n",
    "\n",
    "The constant factor $b$ will not affect the gradient but will needed in practice when we estimate gradients by Monte Carlo (that is roll-outs). We can prove that subtracting $b$ will not change the gradient by using the identity from above again:\n",
    "\n",
    "\\begin{align*}\n",
    "0 & = \\nabla_\\theta 1 \\\\\n",
    "  & = \\nabla_\\theta \\int p_\\theta({\\bf a},{\\bf s}) \\, d{\\bf a} d{\\bf s}\\\\\n",
    "  & = \\int \\nabla_\\theta p_\\theta({\\bf a},{\\bf s}) \\, d{\\bf a}d{\\bf s}\\\\\n",
    "  & = \\int p_\\theta({\\bf a},{\\bf s}) \\nabla_\\theta \\log p_\\theta({\\bf a},{\\bf s}) \\, d{\\bf a}d{\\bf s} \\ .\n",
    "\\end{align*}\n",
    "\n",
    "We cannot evaluate the average over roll-outs analytically but we have an environment simulator that when supplied with our current policy $p_\\theta(a|s)$ can return the sequence of action, states and rewards. This allows us to replace the integral by a Monte Carlo average over $V$ roll-outs\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\mathbb{E}[R|\\theta] \\approx \\frac{1}{V} \\sum_{v=1}^V ( R({\\bf a}^{(v)}, {\\bf s}^{(v)}) - b) \\nabla_\\theta \\log p_\\theta({\\bf a}^{(v)},{\\bf s}^{(v)})\n",
    "$$\n",
    "\n",
    "Note also that the gradient of $\\log p_\\theta({\\bf a}^{(v)},{\\bf s}^{(v)})$ does not depend explicitly on the state distribution:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\log p_\\theta({\\bf a}^{(v)},{\\bf s}^{(v)}) = \\sum_{t=1}^T \\nabla_\\theta \\log p_\\theta(a_{t}|s_{t-1}) \\ .\n",
    "$$\n",
    "\n",
    "We are almost done. As a last step we will use the freedom in the choice of $b$ to select a $b$ that will make the Monte Carlo estimate of the gradient have the lowest possible variance. In other words, the finite Monte Carlo sample give us a noisy gradient and by this correction we can make it vary as little as possible between roll-out draws.\n",
    "\n",
    "The $b$ that minimizes the variances can be found from minimizing the following expression:\n",
    "\n",
    "$$\n",
    "\\int p_\\theta({\\bf a},{\\bf s}) \\, ( R({\\bf a}, {\\bf s}) - b )^2 \\,  |\\nabla_\\theta \\log p_\\theta({\\bf a},{\\bf s})|^2 \\,  d{\\bf a}d{\\bf s} - \\left( \\nabla_\\theta \\mathbb{E}[R|\\theta] \\right)^2 \\ .\n",
    "$$\n",
    "\n",
    "The solution to this problem is\n",
    "\n",
    "$$\n",
    "b = \\frac{\\int p_\\theta({\\bf a},{\\bf s}) \\, R({\\bf a}, {\\bf s}) \\,  |\\nabla_\\theta \\log p_\\theta({\\bf a},{\\bf s})|^2 d{\\bf a}d{\\bf s}}{\\int p_\\theta({\\bf a},{\\bf s}) \\, |\\nabla_\\theta \\log p_\\theta({\\bf a},{\\bf s})|^2 d{\\bf a}d{\\bf s}} \\ .\n",
    "$$\n",
    "\n",
    "We replace this expression by a Monte Carlo average:\n",
    "\n",
    "$$\n",
    "b = \\frac{\\sum_{v=1}^V  R({\\bf a}^{(v)}, {\\bf s}^{(v)}) \\, |\\nabla_\\theta \\log p_\\theta({\\bf a}^{(v)},{\\bf s}^{(v)})|^2}{\\sum_{v=1}^V | \\nabla_\\theta \\log p_\\theta({\\bf a}^{(v)},{\\bf s}^{(v)})|^2}\n",
    "$$\n",
    "\n",
    "In the code below we instead use a time-step dependent baseline correction, $b(s_t)$, as described in [here](https://gym.openai.com/docs/rl#policy-gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.nonlinearities import tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \"\"\"\n",
    "    Reinforcement Learning Agent\n",
    "    \n",
    "    This agent can learn to solve reinforcement learning tasks from\n",
    "    OpenAI Gym by applying the policy gradient method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        # symbolic variables for state, action, and advantage\n",
    "        sym_state = T.fmatrix()\n",
    "        sym_action = T.ivector()\n",
    "        sym_advantage = T.fvector()\n",
    "        # policy network\n",
    "        l_in = InputLayer(shape=(None, n_inputs))\n",
    "        l_hid = DenseLayer(incoming=l_in, num_units=20, nonlinearity=tanh, name='hiddenlayer')\n",
    "        l_out = DenseLayer(incoming=l_hid, num_units=n_outputs, nonlinearity=softmax, name='outputlayer')\n",
    "        # get network output\n",
    "        eval_out = lasagne.layers.get_output(l_out, {l_in: sym_state}, deterministic=True)\n",
    "        # get trainable parameters in the network.\n",
    "        params = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "        # get total number of timesteps\n",
    "        t_total = sym_state.shape[0]\n",
    "        # loss function that we'll differentiate to get the policy gradient\n",
    "        loss = -T.log(eval_out[T.arange(t_total), sym_action]).dot(sym_advantage) / t_total\n",
    "        # learning_rate\n",
    "        learning_rate = T.fscalar()\n",
    "        # get gradients\n",
    "        grads = T.grad(loss, params)\n",
    "        # update function\n",
    "#         updates = lasagne.updates.adagrad(grads, params, learning_rate=learning_rate)\n",
    "        updates = lasagne.updates.momentum(grads, params,learning_rate=learning_rate)\n",
    "        \n",
    "        #New optimizer\n",
    "#         updates = lasagne.updates.sgd(grads, params, learning_rate=learning_rate)\n",
    "        # declare training and evaluation functions\n",
    "        self.f_train = theano.function([sym_state, sym_action, sym_advantage, learning_rate], loss, updates=updates, allow_input_downcast=True)\n",
    "        self.f_eval = theano.function([sym_state], eval_out, allow_input_downcast=True)\n",
    "    \n",
    "    def learn(self, env, n_epochs=100, t_per_batch=10000, traj_t_limit=None,\n",
    "              learning_rate=0.1, discount_factor=1.0, n_early_stop=0):\n",
    "        \"\"\"\n",
    "        Learn the given environment by the policy gradient method.\n",
    "        \"\"\"\n",
    "        self.mean_train_rs = []\n",
    "        self.mean_val_rs = []\n",
    "        self.loss = []\n",
    "        for epoch in xrange(n_epochs):\n",
    "            # 1. collect trajectories until we have at least t_per_batch total timesteps\n",
    "            trajs = []; t_total = 0\n",
    "            while t_total < t_per_batch:\n",
    "                traj = self.get_trajectory(env, traj_t_limit, deterministic=False)\n",
    "                trajs.append(traj)\n",
    "                t_total += len(traj[\"r\"])\n",
    "            all_s = np.concatenate([traj[\"s\"] for traj in trajs])\n",
    "            # 2. compute cumulative discounted rewards (returns)\n",
    "            rets = [self._cumulative_discount(traj[\"r\"], discount_factor) for traj in trajs]\n",
    "            maxlen = max(len(ret) for ret in rets)\n",
    "            padded_rets = [np.concatenate([ret, np.zeros(maxlen-len(ret))]) for ret in rets]\n",
    "            # 3. compute time-dependent baseline\n",
    "            baseline = np.mean(padded_rets, axis=0)\n",
    "            # 4. compute advantages\n",
    "            advs = [ret - baseline[:len(ret)] for ret in rets]\n",
    "            all_a = np.concatenate([traj[\"a\"] for traj in trajs])\n",
    "            all_adv = np.concatenate(advs)\n",
    "            # 5. do policy gradient update step\n",
    "            loss = self.f_train(all_s, all_a, all_adv, learning_rate)\n",
    "            train_rs = np.array([traj[\"r\"].sum() for traj in trajs]) # trajectory total rewards\n",
    "            eplens = np.array([len(traj[\"r\"]) for traj in trajs]) # trajectory lengths\n",
    "            # compute validation reward\n",
    "            val_rs = np.array([self.get_trajectory(env, traj_t_limit, deterministic=True)['r'].sum() for _ in range(10)])\n",
    "            # update stats\n",
    "            self.mean_train_rs.append(train_rs.mean())\n",
    "            self.mean_val_rs.append(val_rs.mean())\n",
    "            self.loss.append(loss)\n",
    "            # print stats\n",
    "            print '%3d mean_train_r: %6.2f mean_val_r: %6.2f loss: %f' % (epoch+1, train_rs.mean(), val_rs.mean(), loss)\n",
    "            # render solution\n",
    "            #self.get_trajectory(env, traj_t_limit, render=True)\n",
    "            # check for early stopping: true if the validation reward has not changed in n_early_stop epochs\n",
    "            if n_early_stop and len(self.mean_val_rs) >= n_early_stop and \\\n",
    "                all([x == self.mean_val_rs[-1] for x in self.mean_val_rs[-n_early_stop:-1]]):\n",
    "                break\n",
    "    \n",
    "    def get_trajectory(self, env, t_limit=None, render=False, deterministic=True):\n",
    "        \"\"\"\n",
    "        Compute trajectroy by iteratively evaluating the agent policy on the environment.\n",
    "        \"\"\"\n",
    "        t_limit = t_limit or env.spec.timestep_limit\n",
    "        s = env.reset()\n",
    "        traj = {'s': [], 'a': [], 'r': [],}\n",
    "        for _ in xrange(t_limit):\n",
    "            a = self.get_action(s, deterministic)\n",
    "            (s, r, done, _) = env.step(a)\n",
    "            traj['s'].append(s)\n",
    "            traj['a'].append(a)\n",
    "            traj['r'].append(r)\n",
    "            if render: env.render()\n",
    "            if done: break\n",
    "        return {'s': np.array(traj['s']), 'a': np.array(traj['a']), 'r': np.array(traj['r'])}\n",
    "    \n",
    "    def get_action(self, s, deterministic=True):\n",
    "        \"\"\"\n",
    "        Evaluate the agent policy to choose an action, a, given state, s.\n",
    "        \"\"\"\n",
    "        # compute action probabilities\n",
    "        prob_a = self.f_eval(s.reshape(1,-1))\n",
    "        if deterministic:\n",
    "            # choose action with highest probability\n",
    "            return prob_a.argmax()\n",
    "        else:\n",
    "            # sample action from distribution\n",
    "            return (np.cumsum(np.asarray(prob_a)) > np.random.rand()).argmax()\n",
    "    \n",
    "    def _cumulative_discount(self, r, gamma):\n",
    "        \"\"\"\n",
    "        Compute the cumulative discounted rewards (returns).\n",
    "        \"\"\"\n",
    "        r_out = np.zeros(len(r), 'float64')\n",
    "        r_out[-1] = r[-1]\n",
    "        for i in reversed(xrange(len(r)-1)):\n",
    "            r_out[i] = r[i] + gamma * r_out[i+1]\n",
    "        return r_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an agent, let's train it to solve the CartPole task.\n",
    "\n",
    "Note: The agent is not guaranteed to learn a good solution every time as the policy gradient method might get stuck in a local optimum -- you may have to do several restarts to find a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-10-03 15:03:55,310] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 mean_train_r:  22.37 mean_val_r:  15.30 loss: 1.798372\n",
      "  2 mean_train_r:  22.28 mean_val_r:  16.10 loss: 2.077622\n",
      "  3 mean_train_r:  21.99 mean_val_r:  21.50 loss: 1.984454\n",
      "  4 mean_train_r:  22.60 mean_val_r:  13.60 loss: 1.839973\n",
      "  5 mean_train_r:  23.23 mean_val_r:  14.20 loss: 2.180260\n",
      "  6 mean_train_r:  22.24 mean_val_r:  16.50 loss: 2.102077\n",
      "  7 mean_train_r:  21.66 mean_val_r:  12.80 loss: 1.787246\n",
      "  8 mean_train_r:  21.84 mean_val_r:  12.30 loss: 1.728649\n",
      "  9 mean_train_r:  22.08 mean_val_r:  11.40 loss: 2.072387\n",
      " 10 mean_train_r:  21.39 mean_val_r:  10.30 loss: 1.904222\n",
      " 11 mean_train_r:  21.75 mean_val_r:  10.20 loss: 1.644869\n",
      " 12 mean_train_r:  22.26 mean_val_r:  10.00 loss: 2.058515\n",
      " 13 mean_train_r:  22.25 mean_val_r:   9.50 loss: 1.753781\n",
      " 14 mean_train_r:  21.65 mean_val_r:   9.80 loss: 1.835190\n",
      " 15 mean_train_r:  20.52 mean_val_r:   9.40 loss: 1.708571\n",
      " 16 mean_train_r:  21.22 mean_val_r:   9.20 loss: 1.824530\n",
      " 17 mean_train_r:  20.77 mean_val_r:   9.40 loss: 1.552855\n",
      " 18 mean_train_r:  21.15 mean_val_r:   9.10 loss: 1.760112\n",
      " 19 mean_train_r:  21.77 mean_val_r:   9.40 loss: 1.829602\n",
      " 20 mean_train_r:  20.86 mean_val_r:   9.40 loss: 1.903938\n",
      " 21 mean_train_r:  20.99 mean_val_r:   9.60 loss: 1.743443\n",
      " 22 mean_train_r:  21.32 mean_val_r:   9.40 loss: 1.935709\n",
      " 23 mean_train_r:  21.81 mean_val_r:  10.00 loss: 2.060258\n",
      " 24 mean_train_r:  20.89 mean_val_r:   9.50 loss: 1.802792\n",
      " 25 mean_train_r:  21.32 mean_val_r:   9.70 loss: 1.707442\n",
      " 26 mean_train_r:  21.19 mean_val_r:   9.80 loss: 1.684434\n",
      " 27 mean_train_r:  21.40 mean_val_r:  10.50 loss: 1.948985\n",
      " 28 mean_train_r:  21.46 mean_val_r:  10.60 loss: 2.002243\n",
      " 29 mean_train_r:  21.91 mean_val_r:  11.00 loss: 1.839993\n",
      " 30 mean_train_r:  21.72 mean_val_r:  10.80 loss: 1.918634\n",
      " 31 mean_train_r:  21.70 mean_val_r:  11.10 loss: 1.745563\n",
      " 32 mean_train_r:  21.28 mean_val_r:  11.60 loss: 1.790897\n",
      " 33 mean_train_r:  22.24 mean_val_r:  15.40 loss: 2.121494\n",
      " 34 mean_train_r:  21.02 mean_val_r:  18.90 loss: 1.688360\n",
      " 35 mean_train_r:  21.29 mean_val_r:  15.60 loss: 1.539137\n",
      " 36 mean_train_r:  21.79 mean_val_r:  24.40 loss: 1.943851\n",
      " 37 mean_train_r:  23.03 mean_val_r:  29.30 loss: 1.990965\n",
      " 38 mean_train_r:  22.68 mean_val_r:  30.00 loss: 1.850163\n",
      " 39 mean_train_r:  21.85 mean_val_r:  39.90 loss: 1.902846\n",
      " 40 mean_train_r:  22.90 mean_val_r:  41.60 loss: 2.229490\n",
      " 41 mean_train_r:  22.69 mean_val_r:  50.20 loss: 2.203548\n",
      " 42 mean_train_r:  23.17 mean_val_r:  49.30 loss: 2.269042\n",
      " 43 mean_train_r:  23.27 mean_val_r:  52.70 loss: 2.151435\n",
      " 44 mean_train_r:  23.59 mean_val_r:  50.60 loss: 2.563522\n",
      " 45 mean_train_r:  24.36 mean_val_r:  53.00 loss: 2.202131\n",
      " 46 mean_train_r:  22.20 mean_val_r:  52.90 loss: 2.014181\n",
      " 47 mean_train_r:  23.55 mean_val_r:  51.20 loss: 2.745610\n",
      " 48 mean_train_r:  22.25 mean_val_r:  54.60 loss: 1.914262\n",
      " 49 mean_train_r:  22.44 mean_val_r:  52.00 loss: 2.231613\n",
      " 50 mean_train_r:  22.95 mean_val_r:  50.10 loss: 2.238292\n",
      " 51 mean_train_r:  23.71 mean_val_r:  52.80 loss: 2.134486\n",
      " 52 mean_train_r:  24.28 mean_val_r:  53.90 loss: 2.436513\n",
      " 53 mean_train_r:  23.49 mean_val_r:  56.00 loss: 2.243642\n",
      " 54 mean_train_r:  23.23 mean_val_r:  46.00 loss: 2.140999\n",
      " 55 mean_train_r:  24.45 mean_val_r:  54.30 loss: 2.644669\n",
      " 56 mean_train_r:  23.83 mean_val_r:  51.90 loss: 2.098098\n",
      " 57 mean_train_r:  24.72 mean_val_r:  61.40 loss: 2.371950\n",
      " 58 mean_train_r:  24.33 mean_val_r:  62.60 loss: 2.426417\n",
      " 59 mean_train_r:  24.57 mean_val_r:  64.10 loss: 2.252185\n",
      " 60 mean_train_r:  22.90 mean_val_r:  99.50 loss: 2.247671\n",
      " 61 mean_train_r:  25.86 mean_val_r: 106.00 loss: 2.383631\n",
      " 62 mean_train_r:  23.56 mean_val_r: 108.30 loss: 2.288538\n",
      " 63 mean_train_r:  24.27 mean_val_r: 143.20 loss: 2.301584\n",
      " 64 mean_train_r:  24.43 mean_val_r: 147.40 loss: 2.272020\n",
      " 65 mean_train_r:  25.17 mean_val_r: 168.80 loss: 2.510540\n",
      " 66 mean_train_r:  25.60 mean_val_r: 159.70 loss: 2.215993\n",
      " 67 mean_train_r:  25.73 mean_val_r: 179.70 loss: 2.317519\n",
      " 68 mean_train_r:  25.84 mean_val_r: 164.00 loss: 2.486572\n",
      " 69 mean_train_r:  27.28 mean_val_r: 165.60 loss: 2.609117\n",
      " 70 mean_train_r:  28.27 mean_val_r: 163.20 loss: 2.907946\n",
      " 71 mean_train_r:  28.78 mean_val_r: 174.80 loss: 2.801548\n",
      " 72 mean_train_r:  27.41 mean_val_r: 167.80 loss: 2.931418\n",
      " 73 mean_train_r:  27.56 mean_val_r: 169.80 loss: 2.745959\n",
      " 74 mean_train_r:  27.77 mean_val_r: 175.30 loss: 2.859333\n",
      " 75 mean_train_r:  27.14 mean_val_r: 168.20 loss: 2.707156\n",
      " 76 mean_train_r:  28.09 mean_val_r: 171.10 loss: 2.517126\n",
      " 77 mean_train_r:  27.06 mean_val_r: 152.40 loss: 2.461190\n",
      " 78 mean_train_r:  28.99 mean_val_r: 162.40 loss: 3.082328\n",
      " 79 mean_train_r:  28.20 mean_val_r: 172.90 loss: 2.878458\n",
      " 80 mean_train_r:  29.03 mean_val_r: 155.20 loss: 2.974003\n",
      " 81 mean_train_r:  28.34 mean_val_r: 177.10 loss: 2.932215\n",
      " 82 mean_train_r:  29.28 mean_val_r: 154.40 loss: 2.968725\n",
      " 83 mean_train_r:  29.86 mean_val_r: 147.80 loss: 2.874111\n",
      " 84 mean_train_r:  28.52 mean_val_r: 166.90 loss: 3.161367\n",
      " 85 mean_train_r:  28.41 mean_val_r: 138.00 loss: 2.628501\n",
      " 86 mean_train_r:  30.16 mean_val_r: 165.80 loss: 3.237112\n",
      " 87 mean_train_r:  29.32 mean_val_r: 142.60 loss: 2.978632\n",
      " 88 mean_train_r:  30.25 mean_val_r: 143.70 loss: 3.066473\n",
      " 89 mean_train_r:  28.25 mean_val_r: 147.70 loss: 2.692458\n",
      " 90 mean_train_r:  28.45 mean_val_r: 137.40 loss: 3.164180\n",
      " 91 mean_train_r:  30.06 mean_val_r: 141.00 loss: 2.836196\n",
      " 92 mean_train_r:  28.97 mean_val_r: 165.40 loss: 2.384565\n",
      " 93 mean_train_r:  28.59 mean_val_r: 149.60 loss: 2.803715\n",
      " 94 mean_train_r:  28.59 mean_val_r: 140.60 loss: 2.947352\n",
      " 95 mean_train_r:  30.78 mean_val_r: 142.80 loss: 2.431974\n",
      " 96 mean_train_r:  32.60 mean_val_r: 128.30 loss: 3.223282\n",
      " 97 mean_train_r:  31.77 mean_val_r: 148.00 loss: 3.203092\n",
      " 98 mean_train_r:  33.83 mean_val_r: 130.30 loss: 3.370457\n",
      " 99 mean_train_r:  32.89 mean_val_r: 138.10 loss: 2.976915\n",
      "100 mean_train_r:  32.79 mean_val_r: 139.50 loss: 3.045801\n"
     ]
    }
   ],
   "source": [
    "# init environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# init agent\n",
    "agent = Agent(n_inputs=env.observation_space.shape[0],\n",
    "              n_outputs=env.action_space.n)\n",
    "# train agent on the environment\n",
    "# agent.learn(env, n_epochs=100, learning_rate=0.05, discount_factor=1,\n",
    "#             t_per_batch=1000, traj_t_limit=env.spec.timestep_limit, n_early_stop=5)\n",
    "#1\n",
    "# agent.learn(env, n_epochs=100, learning_rate=0.05, discount_factor=1,\n",
    "#             t_per_batch=1000, traj_t_limit=500, n_early_stop=5)\n",
    "# This converged but had some ups and downs\n",
    "#agent.learn(env, n_epochs=100, learning_rate=0.1, discount_factor=0.99,\n",
    "#             t_per_batch=10000, traj_t_limit=200, n_early_stop=5)\n",
    "agent.learn(env, n_epochs=100, learning_rate=0.009, discount_factor=0.99,\n",
    "            t_per_batch=10000, traj_t_limit=200, n_early_stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAFHCAYAAAAC3yD+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f061323f050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Format \"01\" is not supported.\nSupported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-232-5c2d8a1e0336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Momentum_0.01\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/adam/anaconda2/envs/deeplearning/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adam/anaconda2/envs/deeplearning/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adam/anaconda2/envs/deeplearning/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;31m# get canvas object and print method for format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m         \u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_output_canvas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m         \u001b[0mprint_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'print_%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adam/anaconda2/envs/deeplearning/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[1;34m(self, format)\u001b[0m\n\u001b[0;32m   2077\u001b[0m         raise ValueError('Format \"%s\" is not supported.\\n'\n\u001b[0;32m   2078\u001b[0m                          \u001b[1;34m'Supported formats: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2079\u001b[1;33m                          '%s.' % (format, ', '.join(formats)))\n\u001b[0m\u001b[0;32m   2080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2081\u001b[0m     def print_figure(self, filename, dpi=None, facecolor='w', edgecolor='w',\n",
      "\u001b[1;31mValueError\u001b[0m: Format \"01\" is not supported.\nSupported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0612572610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation mean reward\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('epochs'); plt.ylabel('mean reward')\n",
    "plt.plot(agent.mean_train_rs, label='training')\n",
    "plt.plot(agent.mean_val_rs, label='validation')\n",
    "plt.xlim((0,len(agent.mean_val_rs)-1))\n",
    "plt.legend(loc=2); plt.grid()\n",
    "_=plt.show()\n",
    "plt.savefig(\"Momentum_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# review solution\n",
    "\n",
    "agent.get_trajectory(env, t_limit=10000, render=True)\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial solution does not learn to solve the task very well. Here are some hints on how to improve the solution:\n",
    "\n",
    "* Increase the trajectory timestep limit to let the simulations look further into the future.\n",
    "* Increase number of timesteps evaluated per batch.\n",
    "* Try different optimization functions.\n",
    "* Adjust the learning rate.\n",
    "* Adjust the discount factor.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Describe the changes you made and and why they should improve the agent. Are you able to get solutions consistently?\n",
    "2. In the plot above you will sometimes see that the validation reward starts out lower than the training reward but later they cross. How can you explain this behavior?\n",
    "3. Explain step by step the algorithm in the `agent.learn` method with particular attention the points denoted 1-5 in the code above.\n",
    "4. Optional: Monitor and submit your best solution to the Gym (see code below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#By decreasing the number of timesteps per batch it was possible to get a solution by updating into the solution\n",
    "#But it seemed very unstable\n",
    "#Adam Optimization was pretty not converging consistantly i think it is because when it is building momentum it overshoots\n",
    "#2.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start monitor\n",
    "# env.monitor.start('cartpole-experiment-1')\n",
    "# for _ in xrange(100):\n",
    "#    agent.get_trajectory(env)\n",
    "# env.monitor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have monitored a solution open a Python shell and use the following command to upload the results to OpenAI Gym:\n",
    "\n",
    "```\n",
    "import gym\n",
    "gym.upload('cartpole-experiment-1', api_key='YOUR_API_KEY')\n",
    "```\n",
    "\n",
    "You can also run the command here in the notebook, but remember to remove the API key before handing in the exercise.\n",
    "\n",
    "You can find your API key at your [OpenAI Gym](https://gym.openai.com/) account page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Playground\n",
    "\n",
    "In this part you can try to learn a solution to an environment from [OpenAI Gym](https://gym.openai.com/) of your own choice. Some environments will require you to adjust the agent code since they have different properties, however, some environments such as 'Acrobot-v1' and 'MountainCar-v0' should work out of the box.\n",
    "\n",
    "Below is some code to get you started.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Describe the environment you have chosen including its state and action space.\n",
    "2. Describe the particular challanges of the environment you have chosen.\n",
    "3. Were you able to train a good solution? How/why not?\n",
    "4. Optional: Monitor and submit your solution to the Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init environment\n",
    "#my_env = gym.make('some-environment')\n",
    "# init agent\n",
    "#my_agent = Agent(n_inputs=my_env.observation_space.shape[0],\n",
    "#              n_outputs=my_env.action_space.n)\n",
    "# train agent on the environment\n",
    "#my_agent.learn(my_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot training and validation mean reward\n",
    "#plt.figure(figsize=(10,5))\n",
    "#plt.xlabel('epochs'); plt.ylabel('mean reward')\n",
    "#plt.plot(my_agent.mean_train_rs, label='training')\n",
    "#plt.plot(my_agent.mean_val_rs, label='validation')\n",
    "#plt.xlim((0,len(my_agent.mean_val_rs)-1))\n",
    "#plt.legend(loc=2); plt.grid()\n",
    "#_=plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# review solution\n",
    "#my_agent.get_trajectory(my_env, t_limit=1000, render=True)\n",
    "#my_env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optional exercises\n",
    "\n",
    "1. Optional: Extend the agent to also work on environments with a continous action space."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
